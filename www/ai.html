<html>
	<head>
		<title>Искусственный интелект</title>
		<meta name="Keywords" content="ai, Artificial intelligence, sea-kg">
	</head>
	<body>
<h1>Проблема создания искусственного интелекта от sea-kg (Evgenii Sopov)</h1>

<h2>Предисловие</h2>
	Я не являюсь ученым это просто попытки исследования и эксперименты
в этом направлении. Вначале мне было интересно просто создать алгоритм
который бы способен был бы восстанавливать образ из праобраза (хотя бы
частично) - речь идет о хэш-функциях. Так как утверждается что невозможно
получить операцию обратного преобразования, с точки зрения математики и
разумности. Это справедливо если принимать метод востановления типа
brute force (метод грубой силы) то есть путь полного перебора входного 
пространства. На примере md5 есть еще различные методы взлома, такие как
поиск коллизий (<a href="https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BB%D0%BB%D0%B8%D0%B7%D0%B8%D1%8F_%D1%85%D0%B5%D1%88-%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8">wiki</a>)
этот метод нашел китайский исследователь. Также существует "оптимизированный"
метод грубой силы: радужные таблицы (<a href="https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B4%D1%83%D0%B6%D0%BD%D0%B0%D1%8F_%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0">wiki<a>) .
Или еще одна оптимизация: перебор по "Словарям" - в отношении паролей
пользователю проще запомнить последовательность символов которая запоминается
а не случайную. В итоге получения оригинального значения требует
большого количества времени, за исключением тех вариантов где они являются
тревиальны. Так как хеш-функции используются в информационной безопастности,
то к ним повышенный интерес.
На всякий случай замечу что хеш-функции используются для хранения паролей
пользователей, и такой механизм очень распространен.
Строиться такая модель защиты:
<ul>
	<li>Чаще менять пароли (так как время переобора слишком велико то если
	менять раз в неделю пароль то злоумышленнник не сможет его за этот срок
	подобрать)</li>
	<li>Использовать более сложные пароли, такие что бы за разумные сроки
	злоумышленник также не смог подобрать</li>
</ul>
<br>
<br>
Вообщем как видите все основывается только на сложности подбора входного значения.
А теперь посмотрим на саму хеш-функцию (напримере md5). Я бы хотел обратить ваше внимание
на следующие моменты: 
<ul>
	<li>на входе бинарные данные определенной длины (не считая дополнения и берем только один блок данных)</li>
	<li>на выходе также бинарные данные определенной длины</li>
	<li>Если взять бинарную "математику" то можно также заметить что операций
для работы над данными (два операнда) не так много, обще приняты такие как AND, OR, XOR. Можно также простроить
дополнительные операции их окажется не так много: 2^3 то есть всего можно придумать 8 операций (3 из них известны).
То есть бинарная математика не такая сложная как высшая математика с интегралами и диффиренциалами.</li>
	<li>возможность замещения одного уровнения на дргугое аналогичное но состоящие из других операций и других последовательностей. Стоп.
	То есть можно попробовать "подобрать" бинарное уравнение очень похожее? Да именно теоритически это возможно!</li>
<br>
<br>
<i><b>Эксперимент 1</b><br>
Просто пытаемся подобрать уравнение для каждого выходного бита подавая на вход все входные биты.<br>
Написан код и проверен, да результат оставлять лучшего но (!) получено необъходимое смещение. Там расчет всяких дисперсий, мат ожиданий 
они имеют отклонения от "случайного" результата а значит теория верна. Только одно но при большом количестве (например 10 млн)
экспериментов результат начинает стремиться к случайному. Вообщем это обрадовало вот только теперь нужно придумать как описать уравнение и 
как оптимально подбирать модифицировать уровнения приближаясь к более точному результату (более высокой вероятности правильного восстановления бит).
</i>
<br>
<br>
Далее я поговорил с одним из студентов и он провел небольшую исследовательскую работу по установлению закономерностей в выходной от входной последовательности. 
Так как использвоались простые варинта для эксперимента (типа поменять один бит) то результат был таким же как и описывается в основе идеи хеш-функций.
На самом деле польза была от его работы: 
<ul>
	<li>Он дал мне новые понятия "образа" и "праобраза"</li>
	<li>И я понял куда смотреть дальше</li>
</ul>
<br>
<br>
В тот момент мне показалось что те люди которые придумывали хеш-функцию
и описывали ее брали только во внимание алгоритмы анализа данных присущие 
только их времени и пространству. И пока не созданно ни одного "адекватного"
алгоритма который бы позволил бы находить более сложные закономерности, иначе бы 
мир начал бы новый скоростной виток в развитии новых технологий.
<br>
<br>
Значи надо думать за рамками предложенного и выходить за пределы досзволенного насколько это возможно.
<b>"Что бы создать интеллект - нужно обладать сверхинтеллектом"</b> незнаю слышал ли я эту фразу или просто придумал сам :).
<br>
<br>
Я начал изучать существующие интересные механизмы и методы для работы над
данными (в том числе бинарными). Первое что мне показалось интересным, и как 
мне казалось что я нашел то что искал, это BDD или бинарные диаграмы решений (<a href="https://ru.wikipedia.org/wiki/%D0%91%D0%B8%D0%BD%D0%B0%D1%80%D0%BD%D0%B0%D1%8F_%D0%B4%D0%B8%D0%B0%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0_%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D0%B9">wiki</a>).
Но я ошибся, да конечно можно составить программу на этой основе но к сожалению для описания всего входного пространства
требуется слишком много оперативной памяти да и к тому же этот путь приведет только к тому что получим 
"радужные таблицы" - а это мы уже проходили я и не могу сказать что это решение с моей точки зрения.
<br>
<br>
<i><b>Эксперимент 2</b>
Я попробовал модифицировать BDD так что бы он смог накапливать и "строить" предположения о том какой входной бит был, но получил то
что просто собирал статистику - не более того.</i><br>
Но это дало мне возможность сформулировать следующие требования к алгоритму:
<ul>
	<li>должен быть обучаемый (благо входных данных для этого превеликое множество)</li>
	<li>должен накапливать результат предыдущего обучения, то есть не сбиваться или не сбиваться но в допустимых пределах</li>
	<li>должен использовать ограниченное количество памяти</li>
	<li>при необходимости модифицировать себя (! это важно)</li>
	<li>сама структура должна быть сериализуемы и десериализуема</li>
<ul>
<br>
<br>
Далее в поисках решения я обратился к интересным алгоритмам таких как генетические и просвещался вот этой вот статьей: <a href="http://habrahabr.ru/post/254759/">Генетический алгоритм — наглядная реализация</a>
Но опять же генетический алгоритм это всего лишь случайный поиск решения на принципе "горячо" или "холодно".
<i><b>Эксперимет 3</b><br>
Использую подход из первого эксперимента, соорудил программку которая бы подбирала уравнения. Но опять не то решение.
Для программы требуется большое количество времени и не менее важное "удачи", и это не правильных подход. Результат оказался хуже первого эксперимента.
Дополнил список требований к алгоритму:
<ul>
	<li>Так как уравнения не простые по своей сути, значит надо что бы модификаци таких уравнения происходила "разумно" не пологаясь на удачу</li>
</ul>
</i>
<br>
<br>
Значит надо пойти дальше и придумать алгоритм не просто для подбора уравнений или
их поиск а сами модификации должны быть результатом поиска. Можно попробовать выразиться так:
Небходимо масштабировать генетический алгоритм и направить его на поиск более удачных модификаций.
<br>
<br>
Для того что бы приступить к следующему эксперименту, я много думал изучал другие альтернативы. Начал задумываться что задача которую я ставлю перед собой
выходит за пределы математики и относиться к созданию "искусственного интелекта" или просто алгоритм который способен находить закономерности и
использовать их что бы прогнозировать. В текущем случае прогнозирвоать входную последовательность бит использую накопленный опыт.
<br>
<br>
По некому стечению остоятельств мне посоветовали книгу "Современный транзактный анализ" автора Стюарт Йен или "Стюарт Ян".
Там много говорится о поведении человека, о неких шаблонах которые мы используем вообщем замечательная книга для простых людей по психологии.
Собственно используя идею шаблонизации алгоритмов и их сочетания мне кажется можно будет создать ИИ. Но речь не совсем об этом.
В долгих размышлениях я также пришел к выводу что создать прогназирующий алгоритм можно только если использовать три состовляющие:
<ul>
	<li>Среда</li>
	<li>Объект</li>
	<li>Взаимодействие</li>
</ul>

Думаю что это не ново. Для смелости я решил почитать <a href="http://www.mari-el.ru/mmlab/home/AI/">Курс лекций по дисциплине "Системы искусственного интеллекта"</a>.
Но прочитав введение что схема подхода к ИИ не совсем верна, так как нельзя рассматривать ИИ только для решения строгих математических задач.
Круг должен быть расширен. Также необходимо помнить о большом количестве времени и ресурсов для создания любых сложных систем.
А что если создать праграмму которая бы писала программы использую входной материал и предыдущий опыт типа как шаблонов а человек бы говорил что верно а что нет.
В таком случае было бы:
<ul>
	<li>"Среда" - программная среда</li>
	<li>"Объект" - программа</li>
	<li>"Взаимодействие" - проверка правильности результата и шаблонизирование действий которые привели к такому результату</li>
</ul>
<br> 
В итоге хочу приступить к Эксперименту 4.<br> 
<i><b>Эксперимент 4</b><br>
Используя 1,2,3 эксперимент необходимо комбинировать различные методы для получения  алгоритма который бы соответсвовал всем требования приведенным выше.
</i>
<br> 
Все равно не удается описать полность мысль в словестной форме. И все пошел я спать, может какие мысли появяться опять.<br>

Надо глянуть: <a href="https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B0%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%BE%D0%B2">Теория автоматов</a>

	</body>
</html>
